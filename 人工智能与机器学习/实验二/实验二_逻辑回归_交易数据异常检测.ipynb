{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5afc219",
   "metadata": {},
   "source": [
    "## 信用卡欺诈检测\n",
    "\n",
    "基于信用卡交易记录数据建立分类模型来预测哪些交易记录是异常的哪些是正常的。\n",
    "\n",
    "### 任务流程：\n",
    "* 加载数据，观察问题\n",
    "* 针对问题给出解决方案\n",
    "* 数据集切分\n",
    "* 评估方法对比\n",
    "* 逻辑回归模型\n",
    "* 建模结果分析\n",
    "* 方案效果对比\n",
    "\n",
    "### 主要解决问题：\n",
    "（1）在此项目中，我们首选对数据进行了观察，发现了其中样本不均衡的问题，其实我们做任务工作之前都一定要先进行数据检查，看看数据有什么问题，针对这些问题来选择解决方案。\n",
    "\n",
    "（2）这里我们提出了两种方法，下采样和过采样，两条路线来进行对比实验，任何实际问题来了之后，我们都不会一条路走到黑的，没有对比就没有伤害，通常都会得到一个基础模型，然后对各种方法进行对比，找到最合适的，所以在任务开始之前，一定得多动脑筋多一手准备，得到的结果才有可选择的余地。\n",
    "\n",
    "（3）在建模之前，需要对数据进行各种预处理的操作，比如数据标准化，缺失值填充等，这些都是必要操作，由于数据本身已经给定了特征，此处我们还没有提到特征工程这个概念，后续实战中我们会逐步引入，其实数据预处理的工作是整个任务中最为最重也是最苦的一个阶段，数据处理的好不好对结果的影响是最大的。\n",
    "\n",
    "（4）先选好评估方法，再进行建模。建模的目的就是为了得到结果，但是我们不可能一次就得到最好的结果，肯定要尝试很多次，所以一定得有一个合适的评估方法，可以用这些通用的，比如Recall，准确率等，也可以根据实际问题自己指定评估指标。\n",
    "\n",
    "（5）选择合适的算法，这里我们使用的是逻辑回归，也详细分析了其中的细节，这是因为我们刚刚讲解完逻辑回归的原理就拿它来练手了，之后我们还会讲解其他算法，并不一定非要用逻辑回归来完成这个任务，其他算法可能效果会更好。但是有一点我希望大家能够理解就是在机器学习中并不是越复杂的算法越实用，恰恰相反，越简单的算法反而应用的越广泛。逻辑回归就是其中一个典型的代表了，简单实用，所以任何分类问题都可以把逻辑回归当做一个待比较的基础模型了。\n",
    "\n",
    "（6）模型的调参也是很重要的，之前我们通过实验也发现了不同的参数可能会对结果产生较大的影响，这一步也是必须的，后续实战内容我们还会来强调调参的细节，这里就简单概述一下了。对于参数我建立大家在使用工具包的时候先看看其API文档，知道每一个参数的意义，再来实验选择合适的参数值。\n",
    "\n",
    "（7）得到的结果一定要和实际任务结合在一起，有时候虽然得到的结果指标还不错，但是实际应用却成了问题，所以测试环节也是必不可少的。到此，这个项目就给大家介绍到这里了，在实践中学习才能成长的更快，建议大家一定使用提供的Notebook代码文件来自己完成一遍上述操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9538f5d3",
   "metadata": {},
   "source": [
    "导入我们的工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e7915",
   "metadata": {},
   "source": [
    "数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d8c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb88398",
   "metadata": {},
   "source": [
    "数据标签分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ced413",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_classes = pd.value_counts(data['Class'], sort = True).sort_index()\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb7ace2",
   "metadata": {},
   "source": [
    "数据标准化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0428e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time','Amount'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb9fd01",
   "metadata": {},
   "source": [
    "下采样方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c120af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, data.columns != 'Class']\n",
    "y = data.iloc[:, data.columns == 'Class']\n",
    "\n",
    "# 得到所有异常样本的索引\n",
    "number_records_fraud = len(data[data.Class == 1])\n",
    "fraud_indices = np.array(data[data.Class == 1].index)\n",
    "\n",
    "# 得到所有正常样本的索引\n",
    "normal_indices = data[data.Class == 0].index\n",
    "\n",
    "# 在正常样本中随机采样出指定个数的样本，并取其索引\n",
    "random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "# 有了正常和异常样本后把它们的索引都拿到手\n",
    "under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n",
    "\n",
    "# 根据索引得到下采样所有样本点\n",
    "under_sample_data = data.iloc[under_sample_indices,:]\n",
    "\n",
    "X_undersample = under_sample_data.iloc[:, under_sample_data.columns != 'Class']\n",
    "y_undersample = under_sample_data.iloc[:, under_sample_data.columns == 'Class']\n",
    "\n",
    "# 下采样 样本比例\n",
    "print(\"正常样本所占整体比例: \", len(under_sample_data[under_sample_data.Class == 0])/len(under_sample_data))\n",
    "print(\"异常样本所占整体比例: \", len(under_sample_data[under_sample_data.Class == 1])/len(under_sample_data))\n",
    "print(\"下采样策略总体样本数量: \", len(under_sample_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc1d5d7",
   "metadata": {},
   "source": [
    "数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae41933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 整个数据集进行划分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "\n",
    "print(\"原始训练集包含样本数量: \", len(X_train))\n",
    "print(\"原始测试集包含样本数量: \", len(X_test))\n",
    "print(\"原始样本总数: \", len(X_train)+len(X_test))\n",
    "\n",
    "# 下采样数据集进行划分\n",
    "X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample\n",
    "                                                                                                   ,y_undersample\n",
    "                                                                                                   ,test_size = 0.3\n",
    "                                                                                                   ,random_state = 0)\n",
    "print(\"\")\n",
    "print(\"下采样训练集包含样本数量: \", len(X_train_undersample))\n",
    "print(\"下采样测试集包含样本数量: \", len(X_test_undersample))\n",
    "print(\"下采样样本总数: \", len(X_train_undersample)+len(X_test_undersample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c60c9f",
   "metadata": {},
   "source": [
    "逻辑回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270982bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall = TP/(TP+FN)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,recall_score,classification_report \n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ecedd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printing_Kfold_scores(x_train_data,y_train_data):\n",
    "    fold = KFold(5,shuffle=False)\n",
    "    #fold = KFold(len(y_train_data),5,shuffle=False) \n",
    "\n",
    "    # 定义不同力度的正则化惩罚力度\n",
    "    c_param_range = [0.01,0.1,1,10,100]\n",
    "    # 展示结果用的表格\n",
    "    results_table = pd.DataFrame(index = range(len(c_param_range),2), columns = ['C_parameter','Mean recall score'])\n",
    "    results_table['C_parameter'] = c_param_range\n",
    "\n",
    "    # k-fold 表示K折的交叉验证，这里会得到两个索引集合: 训练集 = indices[0], 验证集 = indices[1]\n",
    "    j = 0\n",
    "    #循环遍历不同的参数\n",
    "    for c_param in c_param_range:\n",
    "        print('-------------------------------------------')\n",
    "        print('正则化惩罚力度: ', c_param)\n",
    "        print('-------------------------------------------')\n",
    "        print('')\n",
    "\n",
    "        recall_accs = []\n",
    "        \n",
    "        #一步步分解来执行交叉验证\n",
    "        for iteration, indices in enumerate(fold.split(y_train_data),start=1):\n",
    "\n",
    "            # 指定算法模型，并且给定参数\n",
    "            lr = LogisticRegression(C = c_param, penalty = 'l1',solver='liblinear')\n",
    "\n",
    "            # 训练模型，注意索引不要给错了，训练的时候一定传入的是训练集，所以X和Y的索引都是0\n",
    "            lr.fit(x_train_data.iloc[indices[0],:],y_train_data.iloc[indices[0],:].values.ravel())\n",
    "\n",
    "            # 建立好模型后，预测模型结果，这里用的就是验证集，索引为1\n",
    "            y_pred_undersample = lr.predict(x_train_data.iloc[indices[1],:].values)\n",
    "\n",
    "            # 有了预测结果之后就可以来进行评估了，这里recall_score需要传入预测值和真实值。\n",
    "            recall_acc = recall_score(y_train_data.iloc[indices[1],:].values,y_pred_undersample)\n",
    "            # 一会还要算平均，所以把每一步的结果都先保存起来。\n",
    "            recall_accs.append(recall_acc)\n",
    "            print('Iteration ', iteration,': 召回率 = ', recall_acc)\n",
    "\n",
    "        # 当执行完所有的交叉验证后，计算平均结果\n",
    "        results_table.loc[j,'Mean recall score'] = np.mean(recall_accs)\n",
    "        j += 1\n",
    "        print('')\n",
    "        print('平均召回率 ', np.mean(recall_accs))\n",
    "        print('')\n",
    "        \n",
    "    #找到最好的参数，哪一个Recall高，自然就是最好的了。\n",
    "    best_c = results_table.loc[results_table['Mean recall score'].astype('float32').idxmax()]['C_parameter']\n",
    "    \n",
    "    # 打印最好的结果\n",
    "    print('*********************************************************************************')\n",
    "    print('效果最好的模型所选参数 = ', best_c)\n",
    "    print('*********************************************************************************')\n",
    "    \n",
    "    return best_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c1dcda",
   "metadata": {},
   "source": [
    "交叉验证与不同参数结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c = printing_Kfold_scores(X_train_undersample,y_train_undersample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bec2e6",
   "metadata": {},
   "source": [
    "混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6db240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    绘制混淆矩阵\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e109fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "lr = LogisticRegression(C = best_c, penalty = 'l1',solver='liblinear')\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "y_pred_undersample = lr.predict(X_test_undersample.values)\n",
    "\n",
    "# 计算所需值\n",
    "cnf_matrix = confusion_matrix(y_test_undersample,y_pred_undersample)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"召回率: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "# 绘制\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a7436",
   "metadata": {},
   "source": [
    "下采样方案在原始数据集中的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f6f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = best_c, penalty = 'l1',solver='liblinear')\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "y_pred = lr.predict(X_test.values)\n",
    "\n",
    "# 计算所需值\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"召回率: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "# 绘制\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e034189",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c = printing_Kfold_scores(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4b22ea",
   "metadata": {},
   "source": [
    "原始数据直接建模结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1cc9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = best_c, penalty = 'l1',solver='liblinear')\n",
    "lr.fit(X_train,y_train.values.ravel())\n",
    "y_pred_undersample = lr.predict(X_test.values)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred_undersample)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01deaff3",
   "metadata": {},
   "source": [
    "阈值对结果的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用之前最好的参数来进行建模\n",
    "lr = LogisticRegression(C = 0.01, penalty = 'l1',solver='liblinear')\n",
    "\n",
    "# 训练模型，还是用下采样的数据集\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "\n",
    "# 得到预测结果的概率值\n",
    "y_pred_undersample_proba = lr.predict_proba(X_test_undersample.values)\n",
    "\n",
    "#指定不同的阈值\n",
    "thresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "j = 1\n",
    "\n",
    "# 用混淆矩阵来进行展示\n",
    "for i in thresholds:\n",
    "    y_test_predictions_high_recall = y_pred_undersample_proba[:,1] > i\n",
    "    \n",
    "    plt.subplot(3,3,j)\n",
    "    j += 1\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test_undersample,y_test_predictions_high_recall)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    print(\"给定阈值为:\",i,\"时测试集召回率: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "    class_names = [0,1]\n",
    "    plot_confusion_matrix(cnf_matrix\n",
    "                          , classes=class_names\n",
    "                          , title='Threshold >= %s'%i) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baba52a",
   "metadata": {},
   "source": [
    "### SMOTE过采样方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc06d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn\n",
    "#安装库，安装成功后重启软件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d032e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de75bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_cards=pd.read_csv('creditcard.csv')\n",
    "\n",
    "columns=credit_cards.columns\n",
    "# 在特征中去除掉标签\n",
    "features_columns=columns.delete(len(columns)-1)\n",
    "\n",
    "features=credit_cards[features_columns]\n",
    "labels=credit_cards['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, \n",
    "                                                                            labels, \n",
    "                                                                            test_size=0.3, \n",
    "                                                                            random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82245d29",
   "metadata": {},
   "source": [
    "基于SMOTE算法来进行样本生成，这样正例和负例样本数量就是一致的了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f021515",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler=SMOTE(random_state=0)\n",
    "os_features,os_labels=oversampler.fit_resample(features_train,labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a339c96f",
   "metadata": {},
   "source": [
    "训练集样本数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0865479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os_labels[os_labels==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d040e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_features = pd.DataFrame(os_features)\n",
    "os_labels = pd.DataFrame(os_labels)\n",
    "best_c = printing_Kfold_scores(os_features,os_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a20d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = best_c, penalty = 'l1',solver='liblinear')\n",
    "lr.fit(os_features,os_labels.values.ravel())\n",
    "y_pred = lr.predict(features_test.values)\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cnf_matrix = confusion_matrix(labels_test,y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"召回率: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "\n",
    "# 绘制\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b2cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd41cbfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab9db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724564e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f2cb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
